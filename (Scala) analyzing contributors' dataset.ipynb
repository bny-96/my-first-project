{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries on Contributors' dataset with Scala programming language\n",
    "## Student: Pablo Benayas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries, define dataset columns and load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://DESKTOP-UBTP06G:4040\n",
       "SparkContext available as 'sc' (version = 2.4.4, master = local[*], app id = local-1594963453050)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Contributor\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Contributor(\n",
    "                    age: Int,\n",
    "                    workclass: String,\n",
    "                    education: String,\n",
    "                    educationNum: Int,\n",
    "                    maritalStatus: String,\n",
    "                    occupation: String,\n",
    "                    relationship: String,\n",
    "                    race: String,\n",
    "                    sex: String,\n",
    "                    capitalGain: Int,\n",
    "                    capitalLoss: Int,\n",
    "                    hoursPerWeek: Int,\n",
    "                    nativeCountry: String,\n",
    "                    income: String\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.io.Source.fromFile\r\n",
       "readFile: (fichero: String)Seq[Contributor]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.io.Source.fromFile\n",
    "\n",
    "def readFile(fichero: String): Seq[Contributor] = {\n",
    "\n",
    "    def getDefaultInt(v: String, d: Int) = if (v.isEmpty()) d else v.toInt\n",
    "\n",
    "    var i: Int = 0\n",
    "    var rows: Seq[Contributor] = Seq.empty\n",
    "    for (l <- fromFile(fichero).getLines()){\n",
    "      if (i > 0) {\n",
    "        val Array(age, workclass, education, educationNum, maritalStatus, occupation, relationship, race, sex, capitalGain, capitalLoss, hoursPerWeek, nativeCountry, income) =  l.split(\",\")\n",
    "        rows = rows ++ Seq(Contributor(\n",
    "          age = getDefaultInt(age, 0),\n",
    "          workclass = workclass.replace(\"\\\"\", \"\"),\n",
    "          education = education.replace(\"\\\"\", \"\"),\n",
    "          educationNum = getDefaultInt(educationNum, 0),\n",
    "          maritalStatus = maritalStatus.replace(\"\\\"\", \"\"),\n",
    "          occupation = occupation.replace(\"\\\"\", \"\"),\n",
    "          relationship = relationship.replace(\"\\\"\", \"\"),\n",
    "          race = race.replace(\"\\\"\", \"\"),\n",
    "          sex = sex.replace(\"\\\"\", \"\"),\n",
    "          capitalGain = getDefaultInt(capitalGain, 0),\n",
    "          capitalLoss = getDefaultInt(capitalLoss, 0),\n",
    "          hoursPerWeek = getDefaultInt(hoursPerWeek, 0),\n",
    "          nativeCountry = nativeCountry.replace(\"\\\"\", \"\"),\n",
    "          income = income.replace(\"\\\"\", \"\"))) \n",
    "      }\n",
    "      else {\n",
    "        i += 1\n",
    "      }\n",
    "    }\n",
    "    rows\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many rows does dataset have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 32561 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataset: Seq[Contributor] = List(Contributor(39,State-gov,Bachelors,13,Never-married,Adm-clerical,Not-in-family,White,Male,2174,0,40,United-States,<=50K), Contributor(50,Self-emp-not-inc,Bachelors,13,Married-civ-spouse,Exec-managerial,Husband,White,Male,0,0,13,United-States,<=50K), Contributor(38,Private,HS-grad,9,Divorced,Handlers-cleaners,Not-in-family,White,Male,0,0,40,United-States,<=50K), Contributor(53,Private,11th,7,Married-civ-spouse,Handlers-cleaners,Husband,Black,Male,0,0,40,United-States,<=50K), Contributor(28,Private,Bachelors,13,Married-civ-spouse,Prof-specialty,Wife,Black,Female,0,0,40,Cuba,<=50K), Contributor(37,Private,Masters,14,Married-civ-spouse,Exec-managerial,Wife,White,Female,0,0,40,United-States,<=50K), Contributor(49,Private,9th,5,Married-spouse-absent,Other-serv..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataset = readFile(fichero = \"adult.data.clean.csv\") \n",
    "\n",
    "// 1ST METHOD\n",
    "val total_rows = dataset.length\n",
    "println(s\"This dataset has ${total_rows} rows\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 32561 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataset: Seq[Contributor] = List(Contributor(39,State-gov,Bachelors,13,Never-married,Adm-clerical,Not-in-family,White,Male,2174,0,40,United-States,<=50K), Contributor(50,Self-emp-not-inc,Bachelors,13,Married-civ-spouse,Exec-managerial,Husband,White,Male,0,0,13,United-States,<=50K), Contributor(38,Private,HS-grad,9,Divorced,Handlers-cleaners,Not-in-family,White,Male,0,0,40,United-States,<=50K), Contributor(53,Private,11th,7,Married-civ-spouse,Handlers-cleaners,Husband,Black,Male,0,0,40,United-States,<=50K), Contributor(28,Private,Bachelors,13,Married-civ-spouse,Prof-specialty,Wife,Black,Female,0,0,40,Cuba,<=50K), Contributor(37,Private,Masters,14,Married-civ-spouse,Exec-managerial,Wife,White,Female,0,0,40,United-States,<=50K), Contributor(49,Private,9th,5,Married-spouse-absent,Other-serv..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataset = readFile(fichero = \"adult.data.clean.csv\") \n",
    "\n",
    "// 2ND METHOD\n",
    "val total_rows = dataset.toDF().count() \n",
    "println(s\"This dataset has ${total_rows} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean age including age=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.58164675532078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filtered_data: Seq[Int] = List(39, 50, 38, 53, 28, 37, 49, 52, 31, 42, 37, 30, 23, 32, 40, 34, 25, 32, 38, 43, 40, 54, 35, 43, 59, 56, 19, 54, 39, 49, 23, 20, 45, 30, 22, 48, 21, 19, 31, 48, 31, 53, 24, 49, 25, 57, 53, 44, 41, 29, 25, 18, 47, 50, 47, 43, 46, 35, 41, 30, 30, 32, 48, 42, 29, 36, 28, 53, 49, 25, 19, 31, 29, 23, 79, 27, 40, 67, 18, 31, 18, 52, 46, 59, 44, 53, 49, 33, 30, 43, 57, 37, 28, 30, 34, 29, 48, 37, 48, 32, 76, 44, 47, 20, 29, 32, 17, 30, 31, 42, 24, 38, 56, 28, 36, 53, 56, 49, 55, 22, 21, 40, 30, 29, 19, 47, 20, 31, 35, 39, 28, 24, 38, 37, 46, 38, 43, 27, 20, 49, 61, 27, 19, 45, 70, 31, 22, 36, 64, 43, 47, 34, 33, 21, 52, 48, 23, 71, 29, 42, 68, 25, 44, 28, 45, 36, 39, 46, 18, 66, 27, 28, 51, 27, 28, 27, 21, 34, 18, 33, 44, 43, 30, 40, 37, 34, 41, 53, 31, 58, 38, 24..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 1ST METHOD\n",
    "var filtered_data = dataset.map(_.age)\n",
    "val mean_age_with_zeros = filtered_data.sum.toDouble / filtered_data.length.toDouble\n",
    "println(mean_age_with_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|mean age including zeros|\n",
      "+------------------------+\n",
      "|                  38.582|\n",
      "+------------------------+\n",
      "\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mean_age_with_zeros: org.apache.spark.sql.DataFrame = [mean age including zeros: double]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 2ND METHOD\n",
    "val mean_age_with_zeros = dataset.toDF().agg(round(mean(\"age\"),3).alias(\"mean age including zeros\"))\n",
    "println(mean_age_with_zeros.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean age WITHOUT age=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.58164675532078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filtered_data: Seq[Int] = List(39, 50, 38, 53, 28, 37, 49, 52, 31, 42, 37, 30, 23, 32, 40, 34, 25, 32, 38, 43, 40, 54, 35, 43, 59, 56, 19, 54, 39, 49, 23, 20, 45, 30, 22, 48, 21, 19, 31, 48, 31, 53, 24, 49, 25, 57, 53, 44, 41, 29, 25, 18, 47, 50, 47, 43, 46, 35, 41, 30, 30, 32, 48, 42, 29, 36, 28, 53, 49, 25, 19, 31, 29, 23, 79, 27, 40, 67, 18, 31, 18, 52, 46, 59, 44, 53, 49, 33, 30, 43, 57, 37, 28, 30, 34, 29, 48, 37, 48, 32, 76, 44, 47, 20, 29, 32, 17, 30, 31, 42, 24, 38, 56, 28, 36, 53, 56, 49, 55, 22, 21, 40, 30, 29, 19, 47, 20, 31, 35, 39, 28, 24, 38, 37, 46, 38, 43, 27, 20, 49, 61, 27, 19, 45, 70, 31, 22, 36, 64, 43, 47, 34, 33, 21, 52, 48, 23, 71, 29, 42, 68, 25, 44, 28, 45, 36, 39, 46, 18, 66, 27, 28, 51, 27, 28, 27, 21, 34, 18, 33, 44, 43, 30, 40, 37, 34, 41, 53, 31, 58, 38, 24..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 1ST METHOD\n",
    "var filtered_data = dataset.filter(x => x.age > 0).map(_.age)\n",
    "val mean_age_without_zeros = filtered_data.sum.toDouble / filtered_data.length.toDouble\n",
    "println(mean_age_without_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|mean age without age=0|\n",
      "+----------------------+\n",
      "|                38.582|\n",
      "+----------------------+\n",
      "\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mean_age_without_zeros: org.apache.spark.sql.DataFrame = [mean age without age=0: double]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 2ND METHOD\n",
    "val mean_age_without_zeros = dataset.toDF().select(\"age\").where(\"age > 0\").agg(round(mean(\"age\"),3).alias(\"mean age without age=0\"))         \n",
    "println(mean_age_without_zeros.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof there are no zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_zero: Int = 0\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 1ST METHOD\n",
    "val age_zero = dataset.filter(x => x.age == 0).length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 0 rows with zero as age\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age_zero: Long = 0\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 2ND METHOD\n",
    "val age_zero = dataset.toDF().where(\"age == 0\").count()\n",
    "println(s\"there are ${age_zero} rows with zero as age\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How many different countries are contributors from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "different_countries: Int = 42\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 1ST METHOD\n",
    "val different_countries = dataset.map(_.nativeCountry).distinct.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contributors come from 42 different countries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "different_countries: Long = 42\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 2ND METHOD\n",
    "val different_countries = dataset.toDF().select(\"nativeCountry\").distinct().count()\n",
    "println(s\"contributors come from ${different_countries} different countries\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Percentage of contributors by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Seq[String] = List(Male, Female)\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(_.sex).distinct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "66.921 % of contributors are male\n",
      "33.079 % of contributors are female\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_rows: Double = 32561.0\r\n",
       "filter_male: Double = 21790.0\r\n",
       "male_pct: Double = 66.921\r\n",
       "filter_female: Double = 10771.0\r\n",
       "female_pct: Double = 33.079\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 1ST METHOD\n",
    "println(dataset.filter(x => x.sex == \"Male\").length + dataset.filter(x => x.sex == \"Female\").length == dataset.length)  \n",
    "\n",
    "val total_rows: Double = dataset.length\n",
    "\n",
    "val filter_male: Double = dataset.filter(x => x.sex == \"Male\").length\n",
    "val male_pct: Double = BigDecimal(filter_male/total_rows*100).setScale(3, BigDecimal.RoundingMode.HALF_UP).toDouble \n",
    "\n",
    "val filter_female: Double = dataset.filter(x => x.sex == \"Female\").length\n",
    "val female_pct: Double = BigDecimal(filter_female/total_rows*100).setScale(3, BigDecimal.RoundingMode.HALF_UP).toDouble \n",
    "\n",
    "println(s\"${male_pct} % of contributors are male\") \n",
    "println(s\"${female_pct} % of contributors are female\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+\n",
      "|   sex|count|gender_rate|\n",
      "+------+-----+-----------+\n",
      "|  Male|21790|      0.669|\n",
      "|Female|10771|      0.331|\n",
      "+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 2ND METHOD\n",
    "dataset.toDF().groupBy(\"sex\").count().withColumn(\"gender_rate\", round(col(\"count\")/dataset.toDF().count(),3)).sort(col(\"gender_rate\").desc).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "// val x: Double = dataset.filter(x => x.sex == \"Male\").length \n",
    "// val y: Double = dataset.length \n",
    "// (x/y).round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import scala.math.BigDecimal\n",
    "// val x: Double = filter_male/total_rows*100\n",
    "// BigDecimal(x).setScale(3, BigDecimal.RoundingMode.HALF_UP).toDouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Which job generates on average >50K as annual income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+-----------+---------+\n",
      "|       workclass|count_>50K|count_total|ratio (%)|\n",
      "+----------------+----------+-----------+---------+\n",
      "|    Self-emp-inc|       622|       1116|   55.735|\n",
      "|     Federal-gov|       371|        960|   38.646|\n",
      "|       Local-gov|       617|       2093|   29.479|\n",
      "|Self-emp-not-inc|       724|       2541|   28.493|\n",
      "|       State-gov|       353|       1298|   27.196|\n",
      "|         Private|      4963|      22696|   21.867|\n",
      "|                |       191|       1836|   10.403|\n",
      "+----------------+----------+-----------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "more_50K: org.apache.spark.sql.DataFrame = [workclass: string, count: bigint]\r\n",
       "total: org.apache.spark.sql.DataFrame = [workclass: string, count: bigint]\r\n",
       "more_50K_2: org.apache.spark.sql.DataFrame = [workclass: string, count_>50K: bigint]\r\n",
       "total_2: org.apache.spark.sql.DataFrame = [workclass2: string, count_total: bigint]\r\n",
       "table1: org.apache.spark.sql.DataFrame = [workclass: string, count_>50K: bigint ... 1 more field]\r\n",
       "table2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [workclass: string, count_>50K: bigint ... 2 more fields]\r\n",
       "workclass: Array[String] = Array(Self-emp-inc)\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val more_50K = dataset.toDF().where(\"income = '>50K'\").groupBy(\"workclass\").count()//.sort(col(\"count\").desc).show(1)\n",
    "val total = dataset.toDF().groupBy(\"workclass\").count() \n",
    "val more_50K_2 = more_50K.select(col(\"workclass\"), col(\"count\").alias(\"count_>50K\"))\n",
    "val total_2 = total.select(col(\"workclass\").alias(\"workclass2\"), col(\"count\").alias(\"count_total\"))\n",
    "val table1 = more_50K_2.join(total_2,more_50K_2(\"workclass\") ===  total_2(\"workclass2\"),\"inner\").select(col(\"workclass\"),col(\"count_>50K\"),col(\"count_total\"))  \n",
    "val table2 = table1.withColumn(\"ratio (%)\", round(col(\"count_>50K\")/col(\"count_total\")*100, 3)).sort(col(\"ratio (%)\").desc) \n",
    "table2.show() \n",
    "\n",
    "val workclass: Array[String] = table2.select(\"workclass\").limit(1).as[String].collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, Self-emp-inc is greater than 50K\n"
     ]
    }
   ],
   "source": [
    "println(s\"On average, ${workclass(0)} is greater than 50K\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Calculate average years of education for Non-American contributors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+\n",
      "|avg. years of education for Non-Americans contributors|\n",
      "+------------------------------------------------------+\n",
      "|                                                 9.317|\n",
      "+------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.toDF().select(\"nativeCountry\",\"educationNum\").where(\"nativeCountry != 'United-States'\").agg(round(mean(\"educationNum\"),3).alias(\"avg. years of education for Non-Americans contributors\")).show()       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
